{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       2\n",
       "2       3\n",
       "3       4\n",
       "4       5\n",
       "5       6\n",
       "6       7\n",
       "7       8\n",
       "8       9\n",
       "9      10\n",
       "10     11\n",
       "11     12\n",
       "12     13\n",
       "13     14\n",
       "14     15\n",
       "15     16\n",
       "16     17\n",
       "17     18\n",
       "18     19\n",
       "19     20\n",
       "20     21\n",
       "21     22\n",
       "22     23\n",
       "23     24\n",
       "24     25\n",
       "25     26\n",
       "26     27\n",
       "27     28\n",
       "28     29\n",
       "29     30\n",
       "30     31\n",
       "31     32\n",
       "32     33\n",
       "33     34\n",
       "34     35\n",
       "35     36\n",
       "36     37\n",
       "37     38\n",
       "38     39\n",
       "39     40\n",
       "40     41\n",
       "41     42\n",
       "42     43\n",
       "43     44\n",
       "44     45\n",
       "45     46\n",
       "46     47\n",
       "47     48\n",
       "48     49\n",
       "49     50\n",
       "50     51\n",
       "51     52\n",
       "52     53\n",
       "53     54\n",
       "54     55\n",
       "55     56\n",
       "56     57\n",
       "57     58\n",
       "58     59\n",
       "59     60\n",
       "60     61\n",
       "61     62\n",
       "62     63\n",
       "63     64\n",
       "64     65\n",
       "65     66\n",
       "66     67\n",
       "67     68\n",
       "68     69\n",
       "69     70\n",
       "70     71\n",
       "71     72\n",
       "72     73\n",
       "73     74\n",
       "74     75\n",
       "75     76\n",
       "76     77\n",
       "77     78\n",
       "78     79\n",
       "79     80\n",
       "80     81\n",
       "81     82\n",
       "82     83\n",
       "83     84\n",
       "84     85\n",
       "85     86\n",
       "86     87\n",
       "87     88\n",
       "88     89\n",
       "89     90\n",
       "90     91\n",
       "91     92\n",
       "92     93\n",
       "93     94\n",
       "94     95\n",
       "95     96\n",
       "96     97\n",
       "97     98\n",
       "98     99\n",
       "99    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydataset import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "x = np.arange(1,101)\n",
    "x = pd.Series(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.5"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.011491975882016"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.75"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = x.quantile(.25)\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = x.quantile(.50)\n",
    "q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.25"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3 = x.quantile(.75)\n",
    "q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iqr = q3 - q1\n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPkElEQVR4nO3df6zdd13H8efLlmFpcQMmN9hWW00FK2PCLttU1FumcjuN1YTEDvmxBdIsoYKmRkpINIZ/JDiDJIOmmbOghvsHLFC3hknQKxocblVcV0ahbrp1nRsTHd5BHBfe/nFOl7u7++N723N7dz/n+Uhues/3+zn3ft677fOefnvPWaoKSdLq9z0rvQFJ0mAYdElqhEGXpEYYdElqhEGXpEasXalPfPHFF9eWLVs6r3/iiSdYv3798m3oWWoY5x7GmWE45x7GmeHc5j569OhjVfX9c51bsaBv2bKFu+66q/P6yclJxsbGlm9Dz1LDOPcwzgzDOfcwzgznNneS/5jvnJdcJKkRBl2SGmHQJakRBl2SGmHQJakRBl2SGrFo0JPcnOTRJPfMcz5JPpjkZJK7k7xq8NuUJC2myyP0Q8D4Aud3Atv6b3uAD5/7tiRJS7Vo0Kvqc8DXF1iyC/ho9dwBXJTkJYPaoCSpm3T5H1wk2QLcWlUvn+PcrcAfVtU/9G9/FnhXVT3jaaBJ9tB7FM/IyMhlExMTnTc6NTXFhg0bADj20OOd77fajayDR7610rs4v4ZxZhjOuYdxZoCtF655qmdLtWPHjqNVNTrXuUE89T9zHJvzu0RVHQQOAoyOjtZSnvo686my1+6/bal7XLX2XTLNDcdW7BUaVsQwzgzDOfcwzgxwaHz9srzkwSB+yuUUsHnG7U3A6QF8XEnSEgwi6IeBN/d/2uVK4PGqengAH1eStASL/l0nyceAMeDiJKeA3weeA1BVB4AjwNXASeCbwHXLtVlJ0vwWDXpVXbPI+QLePrAdSZLOis8UlaRGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJaoRBl6RGGHRJakSnoCcZT3Iiyckk++c4f2GSv0ryr0mOJ7lu8FuVJC1k0aAnWQPcCOwEtgPXJNk+a9nbgS9V1aXAGHBDkgsGvFdJ0gK6PEK/HDhZVfdV1ZPABLBr1poCnp8kwAbg68D0QHcqSVpQqmrhBcnrgfGqelv/9puAK6pq74w1zwcOAy8Dng/8elXdNsfH2gPsARgZGblsYmKi80anpqbYsGEDAMceerzz/Va7kXXwyLdWehfn1zDODMM59zDODLD1wjVP9WypduzYcbSqRuc6t7bD/TPHsdnfBV4HfBF4LfAjwGeS/H1VfeNpd6o6CBwEGB0drbGxsQ6fvmdycpIz66/d/4zvFc3ad8k0Nxzr8mVqxzDODMM59zDODHBofD1L6V9XXS65nAI2z7i9CTg9a811wC3VcxK4n96jdUnSedIl6HcC25Js7f9D5256l1dmegC4CiDJCPBS4L5BblSStLBF/65TVdNJ9gK3A2uAm6vqeJLr++cPAO8FDiU5Ru8Szbuq6rFl3LckaZZOF6+q6ghwZNaxAzPePw384mC3JklaCp8pKkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1IhOQU8ynuREkpNJ9s+zZizJF5McT/J3g92mJGkxaxdbkGQNcCPwC8Ap4M4kh6vqSzPWXAR8CBivqgeSvHiZ9itJmkeXR+iXAyer6r6qehKYAHbNWvMG4JaqegCgqh4d7DYlSYvpEvSNwIMzbp/qH5vpR4EXJJlMcjTJmwe1QUlSN4tecgEyx7Ga4+NcBlwFrAP+MckdVfWVp32gZA+wB2BkZITJycnOG52amnpq/b5Lpjvfb7UbWTdc88JwzgzDOfcwzgxP79kgdQn6KWDzjNubgNNzrHmsqp4AnkjyOeBS4GlBr6qDwEGA0dHRGhsb67zRyclJzqy/dv9tne+32u27ZJobjnX5MrVjGGeG4Zx7GGcGODS+nqX0r6sul1zuBLYl2ZrkAmA3cHjWmk8BP5NkbZLnAVcA9w52q5KkhSz6rbGqppPsBW4H1gA3V9XxJNf3zx+oqnuTfBq4G/gucFNV3bOcG5ckPV2nv+tU1RHgyKxjB2bdfj/w/sFtTZK0FD5TVJIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqREGXZIa0SnoScaTnEhyMsn+Bda9Osl3krx+cFuUJHWxaNCTrAFuBHYC24FrkmyfZ937gNsHvUlJ0uK6PEK/HDhZVfdV1ZPABLBrjnW/CXwCeHSA+5MkdbS2w5qNwIMzbp8Crpi5IMlG4NeA1wKvnu8DJdkD7AEYGRlhcnKy80anpqaeWr/vkunO91vtRtYN17wwnDPDcM49jDPD03s2SF2CnjmO1azbHwDeVVXfSeZa3r9T1UHgIMDo6GiNjY112yUwOTnJmfXX7r+t8/1Wu32XTHPDsS5fpnYM48wwnHMP48wAh8bXs5T+ddXlv+QpYPOM25uA07PWjAIT/ZhfDFydZLqqPjmITUqSFtcl6HcC25JsBR4CdgNvmLmgqraeeT/JIeBWYy5J59eiQa+q6SR76f30yhrg5qo6nuT6/vkDy7xHSVIHnS5eVdUR4MisY3OGvKquPfdtSZKWymeKSlIjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNcKgS1IjDLokNaJT0JOMJzmR5GSS/XOc/40kd/ffPp/k0sFvVZK0kEWDnmQNcCOwE9gOXJNk+6xl9wM/V1WvAN4LHBz0RiVJC+vyCP1y4GRV3VdVTwITwK6ZC6rq81X13/2bdwCbBrtNSdJiUlULL0heD4xX1dv6t98EXFFVe+dZ/zvAy86sn3VuD7AHYGRk5LKJiYnOG52ammLDhg0AHHvo8c73W+1G1sEj31rpXZxfwzgzDOfcwzgzwNYL1zzVs6XasWPH0aoanevc2g73zxzH5vwukGQH8FbgNXOdr6qD9C/HjI6O1tjYWIdP3zM5OcmZ9dfuv63z/Va7fZdMc8OxLl+mdgzjzDCccw/jzACHxtezlP511eW/5Clg84zbm4DTsxcleQVwE7Czqv5rMNuTJHXV5Rr6ncC2JFuTXADsBg7PXJDkB4FbgDdV1VcGv01J0mIWfYReVdNJ9gK3A2uAm6vqeJLr++cPAL8HvAj4UBKA6fmu8UiSlkeni1dVdQQ4MuvYgRnvvw14xj+CSpLOH58pKkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmN6BT0JONJTiQ5mWT/HOeT5IP983cnedXgtypJWsiiQU+yBrgR2AlsB65Jsn3Wsp3Atv7bHuDDA96nJGkRXR6hXw6crKr7qupJYALYNWvNLuCj1XMHcFGSlwx4r5KkBaztsGYj8OCM26eAKzqs2Qg8PHNRkj30HsEDTCU5sYS9Xgw8toT1TXjHEM49jDPDcM49jDMD7HjfOc39Q/Od6BL0zHGszmINVXUQONjhcz5zE8ldVTV6NvddzYZx7mGcGYZz7mGcGZZv7i6XXE4Bm2fc3gScPos1kqRl1CXodwLbkmxNcgGwGzg8a81h4M39n3a5Eni8qh6e/YEkSctn0UsuVTWdZC9wO7AGuLmqjie5vn/+AHAEuBo4CXwTuG4Z9npWl2oaMIxzD+PMMJxzD+PMsExzp+oZl7olSauQzxSVpEYYdElqxKoI+mIvPdCCJJuT/G2Se5McT/LO/vEXJvlMkq/2f33BSu910JKsSfIvSW7t3x6GmS9K8vEkX+5/zX9ySOb+7f7v73uSfCzJ97Y2d5Kbkzya5J4Zx+adMcm7+207keR15/K5n/VB7/jSAy2YBvZV1Y8BVwJv78+5H/hsVW0DPtu/3Zp3AvfOuD0MM/8J8OmqehlwKb35m547yUbgHcBoVb2c3g9Z7Ka9uQ8B47OOzTlj/8/4buDH+/f5UL95Z+VZH3S6vfTAqldVD1fVP/ff/196f8A30pv1I/1lHwF+dUU2uEySbAJ+CbhpxuHWZ/4+4GeBPwWoqier6n9ofO6+tcC6JGuB59F7vkpTc1fV54Cvzzo834y7gImq+r+qup/eTwpefrafezUEfb6XFWhWki3AK4EvACNnfqa//+uLV3Bry+EDwO8C351xrPWZfxj4GvBn/UtNNyVZT+NzV9VDwB8BD9B7WZDHq+qvaXzuvvlmHGjfVkPQO72sQCuSbAA+AfxWVX1jpfeznJL8MvBoVR1d6b2cZ2uBVwEfrqpXAk+w+i8zLKp/3XgXsBX4AWB9kjeu7K5W3ED7thqCPjQvK5DkOfRi/pdVdUv/8CNnXrmy/+ujK7W/ZfDTwK8k+Xd6l9Jem+QvaHtm6P2ePlVVX+jf/ji9wLc+988D91fV16rq28AtwE/R/tww/4wD7dtqCHqXlx5Y9ZKE3jXVe6vqj2ecOgy8pf/+W4BPne+9LZeqendVbaqqLfS+rn9TVW+k4ZkBquo/gQeTvLR/6CrgSzQ+N71LLVcmeV7/9/tV9P6tqPW5Yf4ZDwO7kzw3yVZ6/0+Jfzrrz1JVz/o3ei8r8BXg34D3rPR+lmnG19D7q9bdwBf7b1cDL6L3r+Jf7f/6wpXe6zLNPwbc2n+/+ZmBnwDu6n+9Pwm8YEjm/gPgy8A9wJ8Dz21tbuBj9P6N4Nv0HoG/daEZgff023YC2Hkun9un/ktSI1bDJRdJUgcGXZIaYdAlqREGXZIaYdAlqREGXZIaYdAlqRH/D8LoLrOzqofAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([1,2,2,3,3,3,4,4,4,4,5,5,5,5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAN6klEQVR4nO3dX4hc93nG8efJSiViR8gXcqeu5HZ1UQKuRRprcF0EYdeEsI1McpMLh8alpWVpaYJLVYrSi4ZclPqiDqGm0IrEKCVyltBEdZDitIZoagKN013HycpVUky6UMvGi6t27XVFi9K3FzMbb9aze/7MnjlvnO8HFs3q/I7OM+/MPBqdmVk5IgQAyOttbQcAAOyOogaA5ChqAEiOogaA5ChqAEhuXxN/6OHDh2NmZqbWvq+//rqmp6f3NtAeIFc15KqGXNW8FXMtLy+/EhG3jtwYEXv+deLEiajr8uXLtfdtErmqIVc15KrmrZhL0lLs0Kmc+gCA5ChqAEiOogaA5ChqAEiOogaA5ChqAEiu1Puoba9Kek3SDyTdjIhek6EAAG+o8oGXuYh4pbEkAICROPUBAMk5SvzHAbb/TdJ/SgpJfx0RZ0esWZC0IEndbvfE4uJirUAbGxvqdDq19m0SuaohVzXkqqYo18q19QmmecOxQ1O15zU3N7e802nlskX9sxHxou2flvSkpI9GxFM7re/1erG0tFQrbL/f1+zsbK19m0SuashVDbmqKco1c+bS5MJscW5+uva8bO9Y1KVOfUTEi8Nf1yRdkHR3rSQAgMoKi9r2tO2Dm5clvVfSlaaDAQAGyrzroyvpgu3N9Y9FxFcbTQUA+KHCoo6I70t65wSyAABG4O15AJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyVHUAJAcRQ0AyZUuattTtr9l+2KTgQAAP6rKM+oHJV1tKggAYLRSRW37qKRTkj7dbBwAwHaOiOJF9t9K+jNJByX9YUTcN2LNgqQFSep2uycWFxdrBdrY2FCn06m1b5PIVQ25qmky18q19dr7dg9IL9+ot+/xI4dqH7dI0bzGuc7jOHZoqvbtODc3txwRvVHb9hXtbPs+SWsRsWx7dqd1EXFW0llJ6vV6MTu749Jd9ft91d23SeSqhlzVNJnrN85cqr3v6eM39fBKYU2MtPprs7WPW6RoXuNc53Gcm59u5HYsc+rjpKT3216VtCjpXtuf2/MkAICRCos6Ij4WEUcjYkbS/ZK+FhEfbjwZAEAS76MGgPQqnXyKiL6kfiNJAAAj8YwaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgOYoaAJKjqAEgucKitv1229+0/W3bz9n+xCSCAQAG9pVY8z+S7o2IDdv7JX3d9hMR8Y2GswEAVKKoIyIkbQy/3T/8iiZDAQDeUOocte0p289KWpP0ZEQ83WgqAMAPefCEueRi+xZJFyR9NCKubNu2IGlBkrrd7onFxcVagTY2NtTpdGrt2yRyVZM119r1db18Y/LHPX7k0K7bm5zXyrX12vt2D6j2vIqu8ziK5jXOdR7HsUNTtW/Hubm55YjojdpWqaglyfbHJb0eEX++05perxdLS0vVUg71+33Nzs7W2rdJ5Koma65Hzj+uh1fKvDSzt1YfOrXr9ibnNXPmUu19Tx+/WXteRdd5HEXzGuc6j+Pc/HTt29H2jkVd5l0ftw6fScv2AUnvkfTdWkkAAJWV+avyNkmftT2lQbF/ISIuNhsLALCpzLs+viPpXRPIAgAYgU8mAkByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByFDUAJEdRA0ByhUVt+3bbl21ftf2c7QcnEQwAMLCvxJqbkk5HxDO2D0patv1kRPxLw9kAACrxjDoiXoqIZ4aXX5N0VdKRpoMBAAYcEeUX2zOSnpJ0Z0S8um3bgqQFSep2uycWFxdrBdrY2FCn06m1b5OazLVybb32vt0D0ss36u17/Mih2sctkvV2XLu+Xnte4yiaNfevaormNc51HsexQ1O1b8e5ubnliOiN2la6qG13JP2jpD+NiC/ttrbX68XS0lLloJLU7/c1Oztba98mNZlr5syl2vuePn5TD6+UOYP1ZqsPnap93CJZb8dHzj9ee17jKJo1969qiuY1znUex7n56dq3o+0di7rUuz5s75f0RUnni0oaALC3yrzrw5I+I+lqRHyy+UgAgK3KPKM+KekBSffafnb49b6GcwEAhgpPPkXE1yV5AlkAACPwyUQASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkKGoASI6iBoDkCova9qO212xfmUQgAMCPKvOM+pyk+YZzAAB2UFjUEfGUpOsTyAIAGMERUbzInpF0MSLu3GXNgqQFSep2uycWFxdrBVq7vq6Xb9TadSzHjxzadfvGxoY6nU4jx165tl573+4B1Z5X0XUeR5PzGgf3r2p+XO9f41zncRw7NFX7dpybm1uOiN6obXtW1Fv1er1YWlqqFHLTI+cf18Mr+2rtO47Vh07tur3f72t2draRY8+cuVR739PHb9aeV9F1HkeT8xoH969qflzvX+Nc53Gcm5+ufTva3rGoedcHACRHUQNAcmXenvd5Sf8k6R22X7D9W83HAgBsKjz5FBEfmkQQAMBonPoAgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgOQoagBIjqIGgORKFbXtedvfs/287TNNhwIAvKGwqG1PSfpLSb8q6Q5JH7J9R9PBAAADZZ5R3y3p+Yj4fkT8r6RFSR9oNhYAYJMjYvcF9gclzUfEbw+/f0DSL0fER7atW5C0MPz2HZK+VzPTYUmv1Ny3SeSqhlzVkKuat2Kun4+IW0dt2FdiZ4/4vTe1e0SclXS2YrA3H8xeiojeuH/OXiNXNeSqhlzV/KTlKnPq4wVJt2/5/qikF/c6CABgtDJF/c+SfsH2Mds/Jel+SV9uNhYAYFPhqY+IuGn7I5L+XtKUpEcj4rkGM419+qQh5KqGXNWQq5qfqFyFLyYCANrFJxMBIDmKGgCSa6WobT9qe832lR222/ZfDD+y/h3bdyXJNWt73fazw68/mVCu221ftn3V9nO2HxyxZuIzK5lr4jOz/Xbb37T97WGuT4xY08a8yuRq5T42PPaU7W/ZvjhiWyuPyRK52npMrtpeGR5zacT2vZ1XREz8S9K7Jd0l6coO298n6QkN3sN9j6Snk+SalXSxhXndJumu4eWDkv5V0h1tz6xkronPbDiDzvDyfklPS7onwbzK5GrlPjY89h9IemzU8dt6TJbI1dZjclXS4V227+m8WnlGHRFPSbq+y5IPSPqbGPiGpFts35YgVysi4qWIeGZ4+TVJVyUd2bZs4jMrmWvihjPYGH67f/i1/VXzNuZVJlcrbB+VdErSp3dY0spjskSurPZ0XlnPUR+R9O9bvn9BCQpg6FeG/3R9wvYvTvrgtmckvUuDZ2NbtTqzXXJJLcxs+M/lZyWtSXoyIlLMq0QuqZ372Kck/ZGk/9the1v3r09p91xSO/MKSf9ge9mDH5+x3Z7OK2tRl/rYegue0eDz+O+U9Iikv5vkwW13JH1R0u9HxKvbN4/YZSIzK8jVyswi4gcR8UsafJL2btt3blvSyrxK5Jr4vGzfJ2ktIpZ3Wzbi9xqdV8lcbT0mT0bEXRr8VNHfs/3ubdv3dF5Zizrlx9Yj4tXNf7pGxFck7bd9eBLHtr1fgzI8HxFfGrGklZkV5WpzZsNj/pekvqT5bZtavY/tlKuleZ2U9H7bqxr8dMx7bX9u25o25lWYq637V0S8OPx1TdIFDX7K6FZ7Oq+sRf1lSb8+fOX0HknrEfFS26Fs/4xtDy/frcH8/mMCx7Wkz0i6GhGf3GHZxGdWJlcbM7N9q+1bhpcPSHqPpO9uW9bGvApztTGviPhYRByNiBkNfkTE1yLiw9uWTXxeZXK1dP+atn1w87Kk90ra/k6xPZ1XmZ+et+dsf16DV2sP235B0sc1eGFFEfFXkr6iwaumz0v6b0m/mSTXByX9ru2bkm5Iuj+GL/E27KSkByStDM9vStIfS/q5LdnamFmZXG3M7DZJn/XgP714m6QvRMRF27+zJVcb8yqTq6372JskmFeZXG3MqyvpwvDvh32SHouIrzY5Lz5CDgDJZT31AQAYoqgBIDmKGgCSo6gBIDmKGgCSo6gBIDmKGgCS+3+QHhk5/iVd1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.hist() # Left Skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841.6666666666666"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run a simulation with python/numpy/pandas\n",
    "- Figure out a way to represent our data\n",
    "- Create a matix of random data (rows = simulations), (columns = trial)\n",
    "- Apply an aggregate function, row-wise to get the results of the sim \n",
    "- Apply a final aggreagte to get our proablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50229"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets answer questions experiamentaly rather than theoretically\n",
    "# whats the probabliity of flipping Heads on  a coin? \n",
    "\n",
    "outcomes = [\"Heads\", \"Tails\"]\n",
    "number_of_simulations = 100_000\n",
    "flips = np.random.choice(outcomes, size = number_of_simulations)\n",
    "\n",
    "# After flipping 100 thousand coins, our experimental probability of flipping Heads is:\n",
    "(flips == \"Heads\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1666"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another example \n",
    "\n",
    "#step 1 rep data outcomes \n",
    "outcomes = [1,2,3,4,5,6]\n",
    "\n",
    "#step 2 create data\n",
    "n_simulations = 10_000\n",
    "\n",
    "rolls = np.random.choice(outcomes, size = n_simulations)\n",
    "rolls\n",
    "\n",
    "# what are the chances of rolling a five? \n",
    "(rolls == 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3275"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the probablity we will roll a five or a six on a six sided die?\n",
    "(rolls >= 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3348"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the prob we will roll less than 3 (but not including 3)\n",
    "(rolls < 3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets roll 2 dice at once\n",
    "1. figure out a way to rep data\n",
    "2. create matrix of random data\n",
    "3. apply an agg row wise \n",
    "4. apply a final agg .mean() to get prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 3],\n",
       "       [3, 1],\n",
       "       [5, 1],\n",
       "       ...,\n",
       "       [4, 4],\n",
       "       [5, 6],\n",
       "       [6, 1]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the odds of rolling snake eyes? \n",
    "\n",
    "#Rep\n",
    "outcomes = [1,2,3,4,5,6]\n",
    "\n",
    "#Create matrix\n",
    "n_simulations = 1_000_000\n",
    "n_trials = 2 # for two die \n",
    "\n",
    "#size arguament can set sim and trial size\n",
    "rolls = np.random.choice(outcomes, size =(n_simulations, n_trials))\n",
    "rolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027651"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply agg row-wise\n",
    "#axis = 1 means sum across the rows axis of the columns = axis = 0\n",
    "sum_of_rolls = rolls.sum(axis=1)\n",
    "\n",
    "#probality of rolling snake eyes\n",
    "(sum_of_rolls == 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027777777777777776"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theoretical = 1/6*1/6\n",
    "theoretical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials = Times experamiment was generated\n",
    "# Simulation = Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.167"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = [1,2,3,4,5,6]\n",
    "rolls = np.random.choice(outcomes, size=(10_000, 2))\n",
    "sum_of_rolls = rolls.sum(axis=1)\n",
    "sum_of_rolls\n",
    "(sum_of_rolls == 7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1366,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.1099,\n",
       " 0.0541,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.0599,\n",
       " 0.1099,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.0541,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.085,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.0799,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.0297,\n",
       " 0.113,\n",
       " 0.085,\n",
       " 0.085,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.085,\n",
       " 0.113,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.0276,\n",
       " 0.1099,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.0276,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.0541,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.113,\n",
       " 0.0297,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.0276,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.0276,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.0276,\n",
       " 0.1366,\n",
       " 0.0297,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.085,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.085,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.0599,\n",
       " 0.085,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.085,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.0541,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.0599,\n",
       " 0.0599,\n",
       " 0.0297,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.0276,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.0297,\n",
       " 0.1099,\n",
       " 0.085,\n",
       " 0.0541,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.0541,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.0276,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.0297,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0297,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.0297,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.0799,\n",
       " 0.1373,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.1366,\n",
       " 0.0297,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.113,\n",
       " 0.0799,\n",
       " 0.0276,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.0297,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.0799,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.0276,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0276,\n",
       " 0.167,\n",
       " 0.0297,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.0541,\n",
       " 0.0799,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.0297,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.0276,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.085,\n",
       " 0.0599,\n",
       " 0.0799,\n",
       " 0.113,\n",
       " 0.0799,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.0541,\n",
       " 0.085,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0297,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.0799,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.0599,\n",
       " 0.0799,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.1099,\n",
       " 0.0276,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.0297,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0276,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.0599,\n",
       " 0.0541,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.0599,\n",
       " 0.0599,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.0297,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.0541,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.0276,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.0297,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.0541,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.0599,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0297,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.0297,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.0799,\n",
       " 0.0276,\n",
       " 0.0541,\n",
       " 0.0799,\n",
       " 0.0799,\n",
       " 0.0541,\n",
       " 0.1373,\n",
       " 0.0599,\n",
       " 0.0599,\n",
       " 0.0297,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.0599,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.0276,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.0297,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.0297,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.0297,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.0276,\n",
       " 0.0799,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0276,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.0276,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.0541,\n",
       " 0.0599,\n",
       " 0.0541,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.0599,\n",
       " 0.0276,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.0799,\n",
       " 0.0276,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.0297,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.0541,\n",
       " 0.0541,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.0297,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.0297,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.0599,\n",
       " 0.085,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.085,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.0276,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0276,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.0276,\n",
       " 0.0541,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.0276,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.0297,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.0297,\n",
       " 0.0541,\n",
       " 0.085,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.085,\n",
       " 0.085,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.0541,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.113,\n",
       " 0.113,\n",
       " 0.085,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.0541,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.0799,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " 0.1373,\n",
       " 0.0541,\n",
       " 0.085,\n",
       " 0.1099,\n",
       " 0.113,\n",
       " 0.0799,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.1099,\n",
       " 0.085,\n",
       " 0.0541,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.1099,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.0799,\n",
       " 0.1099,\n",
       " 0.1373,\n",
       " 0.1366,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1373,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.085,\n",
       " 0.1366,\n",
       " 0.0599,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.0297,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0297,\n",
       " 0.1373,\n",
       " 0.1099,\n",
       " 0.167,\n",
       " 0.1366,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.1099,\n",
       " 0.085,\n",
       " 0.1373,\n",
       " 0.113,\n",
       " 0.1366,\n",
       " 0.085,\n",
       " 0.0799,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.167,\n",
       " 0.0599,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.1366,\n",
       " 0.167,\n",
       " 0.113,\n",
       " 0.0599,\n",
       " 0.1099,\n",
       " 0.0276,\n",
       " 0.167,\n",
       " 0.167,\n",
       " 0.1373,\n",
       " ...]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#possible_sums \n",
    "x = [2,3,4,5,6,7,8,9,10,11,12]\n",
    "y = [(sum_of_rolls == n).mean() for n in sum_of_rolls]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  3,  8,  4, 10,  8,  7,  7, 10,  4])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_rolls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1366, 0.0599, 0.1373, 0.085, 0.0799, 0.1373, 0.167, 0.167, 0.0799, 0.085]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing the odds of proability\n",
    "- setting our own probablitity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49689"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome = [\"Heads\", \"Tails\"]\n",
    "rolls = np.random.choice(outcome, size = (10_000, 1), p = [0.55, 0.45])\n",
    "\n",
    "(flips == \"Heads\").mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Tails', 'Heads', 'Tails', ..., 'Tails', 'Heads', 'Heads'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolls = np.random.choice(outcome, size = (10_000, 2), p = [0.55, 0.45])\n",
    "flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = [1, 0]\n",
    "flips = np.random.choice(outcomes, size=(100_000, 2), p=[0.55, 0.45])\n",
    "flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_heads = flips.sum(axis=1)\n",
    "len(number_of_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30413"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crooked coin proablity to flip on heads.\n",
    "(number_of_heads == 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fair coin number of times flip on heads\n",
    "outcomes = [1, 0]\n",
    "flips = np.random.choice(outcomes, size = (100_000, 2))\n",
    "num_of_heads = flips.sum(axis=1)\n",
    "(num_of_heads == 2).mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add bolean logic to probabilities\n",
    "np.random.normal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([92, 79, 38, ..., 63, 81, 55])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets say we have an average of 0 and a std of 20\n",
    "numbers = np.random.randint(-50, 100, 100_000)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33353"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the proabilitiy that any numbaer is negative?\n",
    "(numbers < 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-88457600ae6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# what is the proability that the number is odd?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# what is the proability that the number is odd?\n",
    "(numbers % 2 != 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative and odd\n",
    "negatives = (numbers < 0)\n",
    "odds = (numbers % 2 != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16625"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(odds & negatives).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66735"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(odds | negatives).mean() # This is an OR operator | # gives more outcomes beacuse OR expands our options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 1, 3, ..., 6, 2, 1]), array([1, 6, 5, ..., 3, 5, 2]))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rolling two dice as a time, prob of rolling an odd and then an even? \n",
    "\n",
    "first_die = np.random.choice([1,2,3,4,5,6], size = 100_000)\n",
    "secound_die = np.random.choice([1,2,3,4,5,6], size = 100_000)\n",
    "\n",
    "first_die, secound_die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to rep the results of the first die as an array of booleans.\n",
    "first_odd = (first_die %2!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "secound_even = (secound_die%2==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, ..., False, False,  True])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_odd_secound_even = (first_odd & secound_even)\n",
    "first_odd_secound_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25019"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_odd_secound_even.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theroetical = .5*.5\n",
    "Theroetical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
